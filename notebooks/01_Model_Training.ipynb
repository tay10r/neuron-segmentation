{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Objective\n",
    "\n",
    "The goal of this project is to generate a segmentation mask for neurons that differentiates the soma and neurites from the background.\n",
    "This primarily useful for automation features, such as morphological measurements, cell counting, etc.\n",
    "We'll be doing this using a variant of U-net, which is a common choice for segmentation tasks in cellular biology. With the model defined,\n",
    "we then train it on the synthetically generated data.\n",
    "\n",
    "*Note: You can use the outline of this notebook to navigate the sections.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "import logging\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Third-Party Libraries\n",
    "import numpy as np\n",
    "import matplotlib. pyplot as plt \n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.v2.functional as FT\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# MLflow for Experiment Tracking and Model Management\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Logging and Define Constants and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-09 03:59:53 | segmentation-notebook | INFO | Logging configured successfully\n"
     ]
    }
   ],
   "source": [
    "# Configure the logging module with desired format and level\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s | %(name)s | %(levelname)s | %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# Create a logger for this notebook\n",
    "logger = logging.getLogger('segmentation-notebook')\n",
    "logger.info(\"Logging configured successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global experiment and run names to be used throughout the notebook\n",
    "PROJECT_NAME = 'neuron_segmentation'\n",
    "RUN_NAME = \"neuron_segmentation_main\"\n",
    "MODEL_NAME = \"neuron_segmentation\"\n",
    "MLFLOW_EXPERIMENT = \"Neuron Segmentation\"\n",
    "# Set up the paths\n",
    "if Path('/phoenix').exists():\n",
    "    # Use directories setup by Z by HP AI Studio\n",
    "    ROOT = Path('/phoenix')\n",
    "    TENSORLOGS_PATH = str(ROOT / 'tensorboard' / 'tensorlogs')\n",
    "    MLFLOW_TRACKING_URI = str(ROOT / 'mlflow')\n",
    "else:\n",
    "    # Use these directories in all other cases.\n",
    "    ROOT = Path('../data')\n",
    "    TENSORLOGS_PATH = str(ROOT / 'tensorboard')\n",
    "    MLFLOW_TRACKING_URI = str(ROOT / 'mlflow')\n",
    "\n",
    "TRAIN_PATH = '../data/imagery/train'\n",
    "VALIDATION_PATH = '../data/imagery/val'\n",
    "BEST_MODEL_PATH = 'best_model.pth'\n",
    "MODEL_PATH = 'neuron_segmentation.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture and Implementation\n",
    "\n",
    "The U-net model, in general, works by successively encoding features until the spatial resolution has been downsized by factor of 4 or 8.\n",
    "After that, the model progressively up samples and concatenates features from prior encoding states. It can be thought of as an auto encoder\n",
    "with skip connections. There are several variations, such as the addition of residual blocks or residual connections, but we will be using\n",
    "the foundational version. The nice thing about U-net is that it is fully convolutional, so even if we train with a small spatial resolution,\n",
    "we can use larger spatial resolutions during deployment.\n",
    "\n",
    "Here is a diagram that illustrates what is happening visually.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"../docs/unet.png\" />\n",
    "</p>\n",
    "\n",
    "Many variants of U-net will go deeper, and many will also have batch normalization and activation functions along side the convolutions.\n",
    "This diagram is a slight simplification in that it only includes the convolution, interpolation, and concatenation functions of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Used for down sizing the input and encoding new features.\n",
    "    This modules all have a stride of 2, a kernel size of 3, and a padding of 1.\n",
    "    So any input signal that is passed to it will have an output whose spatial\n",
    "    resolution is half of that of the input.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        \"\"\"\n",
    "        Initializes the encoder.\n",
    "\n",
    "        :param in_channels: The number of input channels to the module.\n",
    "        :param out_channels: The number of output channels to return by the module.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.norm = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x: Tensor) -> tuple[Tensor, Tensor]:\n",
    "        \"\"\"\n",
    "        Runs the forward pass of the module.\n",
    "\n",
    "        :param x: The input signal to the module.\n",
    "\n",
    "        :returns: The down sampled output of the module, pairsed with the original input signal.\n",
    "                  The original input signal may be used later for skip connections to the decoders.\n",
    "        \"\"\"\n",
    "        skip = x\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        return x, skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    This module is used for up sampling the decoded feature maps by\n",
    "    a factor of two and reconstructing detail. It also handles the\n",
    "    concatenation of previous feature maps (in other words, handles\n",
    "    the skip connections).\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        \"\"\"\n",
    "        Initializes the decoder module.\n",
    "\n",
    "        :param in_channels: The number of input channels for this module.\n",
    "                            Note that this should include the number of channels\n",
    "                            of the signal being concatenated.\n",
    "        :param output_channels: The number of output channels to return from this module.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.norm = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x: Tensor, skip: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Runs the forward pass of this module.\n",
    "\n",
    "        :param x: The input signal to upsample.\n",
    "        :param skip: The skip connection to concatenate to the input signal.\n",
    "\n",
    "        :returns: The output of the module.\n",
    "        \"\"\"\n",
    "        shape = (skip.shape[2], skip.shape[3])\n",
    "        x = F.interpolate(x, size=shape, mode='bilinear')\n",
    "        x = torch.concat((x, skip), dim=1)\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-09 04:02:07 | segmentation-notebook | INFO | U-net initialization done successfully\n"
     ]
    }
   ],
   "source": [
    "class UNet(nn.Module):\n",
    "    \"\"\"\n",
    "    A class for building the architecture of the U-net model.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_features: int = 1):\n",
    "        \"\"\"\n",
    "        Initializes the network.\n",
    "\n",
    "        :param input_features: The number of channels used by the input image. For microscopy, this is generally single\n",
    "                               channel, but it is sometimes 3 channels for widefield microscopy. For confocal microscopy,\n",
    "                               this may be many channels, where each represents a thin slice of the specimen along the Z axis.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            super().__init__()\n",
    "            self.input_features = input_features\n",
    "            self.enc1 = _Encoder(input_features, 16)\n",
    "            self.enc2 = _Encoder(16, 128)\n",
    "            self.enc3 = _Encoder(128, 256)\n",
    "            self.dec3 = _Decoder(256 + 128, 128)\n",
    "            self.dec2 = _Decoder(128 + 16, 16)\n",
    "            self.dec1 = _Decoder(16 + 1, 3)\n",
    "            logger.info(\"U-net initialization done successfully\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error initializing U-net: {e}\")\n",
    "            raise    \n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\" \n",
    "        Implementation of the U-net logic, in which, the input passes through every step of the architecture.\n",
    "\n",
    "        :param x: Input image from microscope.\n",
    "\n",
    "        :returns: The segmentation mask of the input image, at the same spatial resolution.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            x, skip0 = self.enc1(x)\n",
    "            x, skip1 = self.enc2(x)\n",
    "            x, skip2 = self.enc3(x)\n",
    "            x = self.dec3(x, skip2)\n",
    "            x = self.dec2(x, skip1)\n",
    "            x = self.dec1(x, skip0)\n",
    "            return x\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error implementing U-net logic: {e}\")\n",
    "            raise \n",
    "\n",
    "    def smoke_test(self, res: tuple[int, int] = (512, 512), batch_size: int = 4):\n",
    "        \"\"\"\n",
    "        This module is for verifying that the network correctly handles the input tensor.\n",
    "        It primarily catches shape errors and input data type errors.\n",
    "\n",
    "        :param res: The spatial resolution to test with.\n",
    "        :param batch_size: The batch size to test with.\n",
    "        \"\"\"\n",
    "        x = torch.randn((batch_size, self.input_features, res[0], res[1]))\n",
    "        self.eval()\n",
    "        try:\n",
    "            y: Tensor = self.forward(x)\n",
    "            assert(y.shape[0] == batch_size)\n",
    "            assert(y.shape[1] == 3)\n",
    "            assert(y.shape[2] == res[0])\n",
    "            assert(y.shape[3] == res[1])\n",
    "        except Exception as e:\n",
    "            logger.error(f'Failed to run basic network test: {e}')\n",
    "            raise\n",
    "\n",
    "def check_unet():\n",
    "    model = UNet()\n",
    "    model.smoke_test()\n",
    "check_unet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class _Sample:\n",
    "    \"\"\"\n",
    "    This class stores one training sample of the dataset.\n",
    "    It consists of an input image and the target segmentation mask.\n",
    "    The class will either store the path or the tensor. Initially,\n",
    "    the path is only stored. Once the sample is used, the image is\n",
    "    opened and the path is replaced with the image tensor. This is\n",
    "    essentially lazy loading and speeds up training after the first\n",
    "    epoch without having to wait for the whole dataset to be loaded\n",
    "    before starting the training loop.\n",
    "    \"\"\"\n",
    "    image: Path | Tensor\n",
    "    target: Path | Tensor\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    This is a dataset for training the segmentation network.\n",
    "    It reads a directory containing input images and segmentation\n",
    "    mask images. The input images should be PNG files with 5 digits\n",
    "    to indicate the index of the image (with zero padding). For\n",
    "    example: \"00000.png\". Each one of this images should have a\n",
    "    corresponding \"{index:05}_mask.png\", which is the target segmentation\n",
    "    mask that the network should learn to reproduce. For example,\n",
    "    the input image \"00123.png\" should have a corresponding \"00123_mask.png\".\n",
    "    The segmentation mask should consist of three channels: red, green and blue.\n",
    "    Red represents the soma, green represents a neurite, and blue represents\n",
    "    the background.\n",
    "    \"\"\"\n",
    "    def __init__(self, img_dir: Path, cache: bool):\n",
    "        \"\"\"\n",
    "        Initialize the segmentation dataset.\n",
    "\n",
    "        :param img_dir: Image directory containing input images and target segmentation masks.\n",
    "        :param cache: Whether or not to cache the images in memory.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            super().__init__()\n",
    "            self.cache = cache\n",
    "            self.samples: list[_Sample] = []\n",
    "            for entry in img_dir.glob('*'):\n",
    "                if 'mask' in entry.stem:\n",
    "                    continue\n",
    "                index = int(str(entry.stem))\n",
    "                mask_entry = img_dir / f'{index:05}_mask.png'\n",
    "                self.samples.append(_Sample(image=entry, target=mask_entry))\n",
    "\n",
    "            logger.info(f\"Segmentation dataset initialization done successfully (num_samples={len(self.samples)})\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error initializing segmentation dataset: {e}\")\n",
    "            raise\n",
    "\n",
    "    def __getitem__(self, index: int) -> tuple[Tensor, Tensor]:\n",
    "        \"\"\"\n",
    "        Gets an input image and the target segmentation mask.\n",
    "\n",
    "        :index: The index of the sample in the dataset.\n",
    "\n",
    "        :returns: An input image and a target segmentation mask.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            sample = self.samples[index]\n",
    "            if self.cache:\n",
    "                if isinstance(sample.image, Path):\n",
    "                    sample.image = read_image(str(sample.image)).float() * (1.0 / 255.0)\n",
    "                if isinstance(sample.target, Path):\n",
    "                    sample.target = read_image(str(sample.target)).float() * (1.0 / 255.0)\n",
    "                image = sample.image\n",
    "                target = sample.target\n",
    "                return image, target\n",
    "            else:\n",
    "                image = read_image(str(sample.image)) * (1.0 / 255.0)\n",
    "                target = read_image(str(sample.target)) * (1.0 / 255.0)\n",
    "                return image, target\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error getting sample: {e}\")\n",
    "            raise\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Get the number of input and output pairs.\n",
    "\n",
    "        :returns: The number of input and output pairs.\n",
    "        \"\"\"\n",
    "        return len(self.samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainUNet(object):\n",
    "    def __init__(self,\n",
    "                 model: nn.Module,\n",
    "                 optimizer: optim.Optimizer,\n",
    "                 train_loader: DataLoader,\n",
    "                 val_loader: DataLoader,\n",
    "                 device):\n",
    "        \"\"\"\n",
    "        Initialize the model training object.\n",
    "\n",
    "        :model: U-net model.\n",
    "        :criterion: Measures the error between the output and the real value.\n",
    "        :optimizer : Adjusts model weights for loss minimization.\n",
    "        :train_loader: Training batches.\n",
    "        :val_loader: Validation batches.\n",
    "        :n_epochs: Number of epochs for the training.\n",
    "        :device: Where the model and data will be processed.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.model = model\n",
    "            self.optimizer = optimizer\n",
    "            self.train_loader = train_loader\n",
    "            self.val_loader = val_loader\n",
    "            self.device = device\n",
    "            self.log_dir = TENSORLOGS_PATH\n",
    "            self.mlflow_exp_name = PROJECT_NAME\n",
    "            self.tb_writer = torch.utils.tensorboard.SummaryWriter()\n",
    "            self.best_metric = float('inf')\n",
    "            self.best_epoch = -1\n",
    "\n",
    "            logger.info('Training object initialization done successfully')\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f'  Error initializing training object: {e}')\n",
    "\n",
    "    def train(self, num_epochs: int = 100):\n",
    "        \"\"\"\n",
    "        Train the U-net model\n",
    "\n",
    "        :param num_epochs: The number of epochs to train the model for.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            writer = SummaryWriter(self.log_dir)\n",
    "            mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "            mlflow.set_experiment(self.mlflow_exp_name)\n",
    "\n",
    "            self.model = self.model.to(self.device)\n",
    "            self.model.train()\n",
    "\n",
    "            best_metrics: dict[str, float] | None = None\n",
    "\n",
    "            for epoch in range(num_epochs):\n",
    "                running_loss = 0.0\n",
    "                count = 0\n",
    "                loader = tqdm(self.train_loader)\n",
    "                for i, (image, target) in enumerate(loader):\n",
    "                    image: Tensor = image.to(self.device)\n",
    "                    target: Tensor = target.to(self.device)\n",
    "\n",
    "                    predicted = self.model(image)\n",
    "                    loss: Tensor = F.cross_entropy(predicted, target)\n",
    "\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "\n",
    "                    running_loss += loss.item()\n",
    "                    count += 1\n",
    "                    loader.set_description(f'Train Loss: {running_loss / count}')\n",
    "\n",
    "                self.log_images_to_tensorboard(writer, epoch)\n",
    "\n",
    "                # Validate on the validation set\n",
    "                metrics = self.validate()\n",
    "\n",
    "                # Log metrics to Tensorboard\n",
    "                for metric, value in metrics.items():\n",
    "                    writer.add_scalar(metric, value, epoch)\n",
    "\n",
    "                if running_loss < self.best_metric:\n",
    "                    torch.save(self.model.state_dict(), BEST_MODEL_PATH)\n",
    "                    best_metrics = metrics\n",
    "\n",
    "            writer.close()\n",
    "\n",
    "            with mlflow.start_run(run_name = RUN_NAME) as run:\n",
    "                logger.info(run.info.run_id)\n",
    "                if best_metrics is not None:\n",
    "                    for metric_name, value in best_metrics.items():\n",
    "                        mlflow.log_metric(metric_name, value)\n",
    "                mlflow.register_model(model_uri = f'runs:/{run.info.run_id}/neuron-segmentation', name = MODEL_NAME)\n",
    "\n",
    "            logger.info('Training done.')\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f'Error training model: {e}')\n",
    "\n",
    "    def log_images_to_tensorboard(self, writer, epoch):\n",
    "        \"\"\"\n",
    "        Log images on the tensorboard to monitor model training.\n",
    "\n",
    "        :writer: Instance of the tensorboard SummaryWriter class, used to \"write\" in a format that the tensorboard can \"read\"\n",
    "        :epoch: Epoch of each image\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                # Get a batch from the validation set\n",
    "                image, target = next(iter(self.val_loader))\n",
    "                image: Tensor = image.to(self.device)\n",
    "                target: Tensor = target.to(self.device)\n",
    "\n",
    "                # Forward pass\n",
    "                predicted = self.model(image)\n",
    "                grid = make_grid(torch.concat((image.expand(-1, 3, -1, -1), predicted, target), dim=0), n_rows=4)\n",
    "                writer.add_image(f'Result', grid, epoch)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f'Error logging on tensorboard: {e}')\n",
    "\n",
    "    @staticmethod\n",
    "    def __3_class_dice(pred: torch.Tensor, target: torch.Tensor, eps: float = 1e-6) -> Tensor:\n",
    "        \"\"\"\n",
    "        Computes Dice coefficient for 3-class segmentation.\n",
    "\n",
    "        :pred: Predicted class scores, shape [N, 3, H, W].\n",
    "        :target: Ground truth, shape [N, 3, H, W].\n",
    "        :eps: Smoothing term.\n",
    "\n",
    "        :returns: Dice score per class.\n",
    "        \"\"\"\n",
    "        pred_flat = pred.view(pred.shape[0], pred.shape[1], -1)\n",
    "        target_flat = target.view(target.shape[0], target.shape[1], -1)\n",
    "\n",
    "        intersection = (pred_flat * target_flat).sum(dim=2)\n",
    "        union = pred_flat.sum(dim=2) + target_flat.sum(dim=2)\n",
    "\n",
    "        dice = (2 * intersection + eps) / (union + eps)\n",
    "        return dice.mean(dim=0)\n",
    "\n",
    "    def validate(self) -> dict[str, float]:\n",
    "        \"\"\"\n",
    "        Validates training by calculating some metrics that were defined.\n",
    "\n",
    "        :returns: Metrics used to evaluate training.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_loss = 0.0\n",
    "                val_loop = tqdm(self.val_loader)\n",
    "                count = 0\n",
    "                dice_scores_sum = [0.0, 0.0, 0.0]\n",
    "                for (image, target) in val_loop:\n",
    "                    image: Tensor = image.to(self.device)\n",
    "                    target: Tensor = target.to(self.device)\n",
    "                    predicted = self.model(image)\n",
    "                    loss: Tensor = F.cross_entropy(predicted, target)\n",
    "                    dice_scores = TrainUNet.__3_class_dice(predicted, target)\n",
    "                    dice_scores_sum[0] += dice_scores[0].item()\n",
    "                    dice_scores_sum[1] += dice_scores[1].item()\n",
    "                    dice_scores_sum[2] += dice_scores[2].item()\n",
    "                    val_loss += loss.item()\n",
    "                    count += 1\n",
    "                    val_loop.set_description(f'Validation: Loss = {val_loss / count}')\n",
    "                val_loop.close()\n",
    "                dice_soma = dice_scores_sum[0] / count\n",
    "                dice_neurites = dice_scores_sum[1] / count\n",
    "                dice_background = dice_scores_sum[2] / count\n",
    "                return {\n",
    "                    'val_loss': val_loss / len(self.val_loader),\n",
    "                    'dice_soma': dice_soma,\n",
    "                    'dice_neurites': dice_neurites,\n",
    "                    'dice_background': dice_background\n",
    "                }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f'Error validating training: {e}')\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation metrics used are:\n",
    "\n",
    "|          Metric | Description\n",
    "|-----------------|------------\n",
    "|      Train Loss | Evaluates the error in the data on which the model is learning. A decreasing loss means that the model is learning and improving\n",
    "| Validation Loss | Evaluates the performance of the model on the validation set. It indicates how well the model can generalize to new data. In this case, it measures the error on the validation data. The lower the validation loss value, the better, meaning that the model is generalizing well.\n",
    "|      Dice Score | This is a metric used to evaluate the performance of the network by computing the overlap between the predicted result and the ground truth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-09 04:07:42 | segmentation-notebook | INFO | cuda\n",
      "2025-06-09 04:07:43 | segmentation-notebook | INFO | Segmentation dataset initialization done successfully (num_samples=2240)\n",
      "2025-06-09 04:07:43 | segmentation-notebook | INFO | Segmentation dataset initialization done successfully (num_samples=600)\n",
      "2025-06-09 04:07:43 | segmentation-notebook | INFO | U-net initialization done successfully\n",
      "2025-06-09 04:07:43 | segmentation-notebook | INFO | Training object initialization done successfully\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de42028b1534ecf83a7d61f9fe775a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-09 04:10:13 | segmentation-notebook | ERROR | Error logging on tensorboard: make_grid() got an unexpected keyword argument 'nrows'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90b78b581fb45a489c06c5b1914fe81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-09 04:10:45 | segmentation-notebook | INFO | 8a55f959011949b8a19b9cb086d5d6bc\n",
      "Registered model 'neuron_segmentation' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'neuron_segmentation'.\n",
      "2025-06-09 04:10:45 | segmentation-notebook | INFO | Training done.\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    train_dir = TRAIN_PATH\n",
    "    val_dir = VALIDATION_PATH\n",
    "    scale = 4\n",
    "    batch_size = 4\n",
    "    epochs = 1\n",
    "    cache = False\n",
    "\n",
    "args = Args()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logger.info(device)\n",
    "\n",
    "mlflow.set_experiment(MLFLOW_EXPERIMENT)\n",
    "\n",
    "# Load training dataset\n",
    "train_dataset = SegmentationDataset(Path(args.train_dir), args.cache)\n",
    "\n",
    "# Load validation dataset\n",
    "val_dataset = SegmentationDataset(Path(args.val_dir), args.cache)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "model = UNet(input_features=1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0001)\n",
    "trainer = TrainUNet(model, optimizer, train_loader, val_loader, device)\n",
    "trainer.train(args.epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-09 03:32:23 | segmentation-notebook | INFO | U-net initialization done successfully\n",
      "/tmp/ipykernel_193/1247619192.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH), weights_only=True)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Module.load_state_dict() got an unexpected keyword argument 'weights_only'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m UNet(input_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      6\u001b[0m x_batch, y_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(val_loader))\n",
      "\u001b[0;31mTypeError\u001b[0m: Module.load_state_dict() got an unexpected keyword argument 'weights_only'"
     ]
    }
   ],
   "source": [
    "model = UNet(input_features=1)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model.eval()\n",
    "\n",
    "x_batch, y_batch = next(iter(val_loader))\n",
    "x, y = x_batch[0], y_batch[0]\n",
    "x = x.to(device).unsqueeze(dim=0)\n",
    "y = y.unsqueeze(dim=0)\n",
    "pred = F.softmax(model(x))\n",
    "pred = pred.cpu()\n",
    "\n",
    "# Convert tensors to numpy arrays \n",
    "y = y[0].numpy().transpose(1, 2, 0)\n",
    "pred = pred[0].detach().numpy().transpose(1, 2, 0)\n",
    "\n",
    "# Plot the images\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axes[0].imshow(y)\n",
    "axes[0].set_title('Ground Truth')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(pred)\n",
    "axes[1].set_title('Predicted')\n",
    "axes[1].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Built with ❤️ using Z by HP AI Studio."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
